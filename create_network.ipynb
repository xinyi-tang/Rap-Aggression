{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,re\n",
    "import requests as rq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import spotipy\n",
    "import json\n",
    "from netwulf import visualize\n",
    "import community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rappers():\n",
    "    \n",
    "    def validate(name):\n",
    "        # checks if the name has a\n",
    "        illegal_chars = \"|?:^*\\\"\"\n",
    "\n",
    "        for c in illegal_chars:\n",
    "            if c == '|':\n",
    "                if name.find(c) > 0:\n",
    "                    name = name.split(\"|\")[1]\n",
    "            if c == \"\\\"\":\n",
    "                if name.find(c) > 0:\n",
    "                    name = name.replace(r'\"','',2)\n",
    "            else: \n",
    "                name = name.replace(c,'')\n",
    "        return name\n",
    "    \n",
    "    with open(\"data/rappers.txt\", \"r\", encoding='utf-8') as f:\n",
    "        rappers = f.read()\n",
    "        \n",
    "    return [validate(rapper).strip() for rapper in rappers.split(\"\\n\")]\n",
    "rappers = get_rappers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_collaborators(r):\n",
    "    with open((\"data/albums/%s.txt\" % r), \"r\", encoding='utf-8') as fp:\n",
    "        albums = eval(fp.read())\n",
    "        \n",
    "    artists = []\n",
    "    for album in albums: \n",
    "        for artist in album['tracks']:\n",
    "            for a in artist['collaborators']:\n",
    "                artists.append(a)\n",
    "    return artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collaborator_count(collaborators, r):\n",
    "    #creating a dictionary from the collaborators to count the number of collaborations for weighted edges\n",
    "    col_dict = {}\n",
    "    for c in collaborators:\n",
    "        #don't include self as a rapper\n",
    "        if c == r: \n",
    "            continue\n",
    "        #add new collaborators to the dict with a count of 1\n",
    "        if c not in col_dict: \n",
    "            col_dict[c] =  1\n",
    "        #add one to the count of previous collaborators\n",
    "        else: \n",
    "            col_dict[c] += 1\n",
    "    return col_dict  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_network(network):\n",
    "    with open((\"data/networks/%s.json\" % network), \"w\") as fp:\n",
    "        json.dump(nx.node_link_data(network), fp)\n",
    "        print(\"network saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_senti():\n",
    "    # this function returns a dictionary of the aggression scores with artists names as the keys\n",
    "    # it also subtracts the aggression scores from 1, so that all the values will be positive and the \n",
    "    with open('data/senti.txt', \"r\") as fp:\n",
    "        senti_scores = eval(fp.read())\n",
    "        for k in senti_scores:\n",
    "            # subtract from one so that they are all positive and the more aggressive scores (already negative) are larger\n",
    "            # exponant 10 so that the differences between aggression scores is easier to visualize \n",
    "            (senti_scores[k]) = (1 - (senti_scores[k])) ** 10        \n",
    "    return senti_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lim_artists():\n",
    "    # this function creates a limited list of artists from the data we were \n",
    "    # able to scrape on lyrics so we can make a preliminary network\n",
    "    with open('data/senti.txt', \"r\") as fp:\n",
    "        senti_scores = eval(fp.read())\n",
    "    return senti_scores.keys()\n",
    "lim_artists = get_lim_artists()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "464"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lim_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network(rappers, network): \n",
    "    \n",
    "    for r in list(rappers):\n",
    "        try: \n",
    "            #get the collaborators from the data file in a list \n",
    "            collaborators = find_collaborators(r)\n",
    "            \n",
    "        except IndexError: \n",
    "            errors.append(r)\n",
    "            continue\n",
    "        except SyntaxError:\n",
    "            errors.append(r)\n",
    "            continue\n",
    "        \n",
    "        col_dict = get_collaborator_count(collaborators, r)\n",
    "        \n",
    "        for c in set(collaborators):\n",
    "            #don't include self as a collaborator\n",
    "            if c == r: \n",
    "                continue\n",
    "            if c not in list(rappers):\n",
    "                continue\n",
    "            else:\n",
    "                #get the weight for the edge as number of collaborations from dict\n",
    "                w = col_dict[c]\n",
    "                #add the weighted edges\n",
    "                network.add_edge(r,c,weight=w)\n",
    "\n",
    "                if network.degree(c) == 1 and w == 1:\n",
    "                    network.remove_node(c)\n",
    "    \n",
    "    #set the node sizes to the aggression scores\n",
    "    node_sizes = get_senti()\n",
    "    nx.set_node_attributes(network, node_sizes, 'size')\n",
    "    \n",
    "    #sort the network into communities using the python-louvain method\n",
    "    bb = community.best_partition(network)  # dict of node-community pairs\n",
    "    nx.set_node_attributes(network, bb, 'group')\n",
    "    \n",
    "    '''#save the network data in a file so that you can look at it later\n",
    "    with open((\"data/networks/%s.json\" % network), \"w\") as fp:\n",
    "        json.dump(nx.node_link_data(network), fp)\n",
    "        print(\"network saved\")\n",
    "    #save_network(network)'''\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "network saved\n"
     ]
    }
   ],
   "source": [
    "prelim_aggression_network_464 = nx.Graph()\n",
    "create_network(lim_artists, prelim_aggression_network_464)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/networks/prelim_aggression_network_464.json', 'w') as fp:\n",
    "    json.dump(nx.node_link_data(prelim_aggression_network_464), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in create_network.ipynb.\n",
      "The file will have its original line endings in your working directory.\n"
     ]
    }
   ],
   "source": [
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[master d90b9bd] node sizes added\n",
      " 3 files changed, 1003 insertions(+), 1239 deletions(-)\n",
      " rewrite create_network.ipynb (87%)\n",
      " rewrite data/networks/.json (96%)\n",
      " create mode 100644 data/networks/prelim_aggression_network_633.json\n"
     ]
    }
   ],
   "source": [
    "!git commit -m \"node sizes added\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing data/.ipynb_checkpoints/senti-checkpoint.txt\n",
      "Merge made by the 'recursive' strategy.\n",
      " data/.ipynb_checkpoints/dictionay-checkpoint.txt |   1 +\n",
      " data/.ipynb_checkpoints/done-checkpoint.txt      | 169 -----------------------\n",
      " data/.ipynb_checkpoints/senti-checkpoint.txt     |   1 -\n",
      " data/done.txt                                    | 169 -----------------------\n",
      " data/senti.txt                                   |   2 +-\n",
      " lyrics_analysis.ipynb                            |  61 ++++----\n",
      " 6 files changed, 38 insertions(+), 365 deletions(-)\n",
      " create mode 100644 data/.ipynb_checkpoints/dictionay-checkpoint.txt\n",
      " delete mode 100644 data/.ipynb_checkpoints/senti-checkpoint.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From https://github.com/allengueco/rap_aggression\n",
      " * branch            master     -> FETCH_HEAD\n",
      "   5744406..dbd465e  master     -> origin/master\n"
     ]
    }
   ],
   "source": [
    "!git pull origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To https://github.com/allengueco/rap_aggression.git\n",
      "   dbd465e..33e691b  master -> master\n"
     ]
    }
   ],
   "source": [
    "!git push origin master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
